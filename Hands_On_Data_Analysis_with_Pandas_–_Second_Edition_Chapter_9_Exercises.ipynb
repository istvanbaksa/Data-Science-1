{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hands-On Data Analysis with Pandas – Second Edition Chapter 9 Exercises.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNzJJJIPitScx8a9azF2eVa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/istvanbaksa/Data-Science-1/blob/main/Hands_On_Data_Analysis_with_Pandas_%E2%80%93_Second_Edition_Chapter_9_Exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hands-On Data Analysis with Pandas – Second Edition Chapter 9 Exercises"
      ],
      "metadata": {
        "id": "vkvJGnSGoMZI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ft8MrzWdoG3k"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "1. Build a clustering model to distinguish between red and white wine by their\n",
        "chemical properties:\n",
        "a) Combine the red and white wine datasets (data/winequality-red.csv\n",
        "and data/winequality-white.csv, respectively) and add a column for the\n",
        "kind of wine (red or white).\n",
        "b) Perform some initial EDA.\n",
        "c) Build and fit a pipeline that scales the data and then uses k-means clustering to\n",
        "make two clusters. Be sure not to use the quality column.\n",
        "d) Use the Fowlkes-Mallows Index (the fowlkes_mallows_score() function\n",
        "is in sklearn.metrics) to evaluate how well k-means is able to make the\n",
        "distinction between red and white wine.\n",
        "e) Find the center of each cluster.\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import fowlkes_mallows_score\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "\n",
        "pd.set_option('display.max_rows', 200)\n",
        "pd.set_option('display.max_columns', 200)\n",
        "\n",
        "winew = pd.read_csv('https://raw.githubusercontent.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/master/ch_09/data/winequality-white.csv', delimiter = ';')\n",
        "winer = pd.read_csv('https://raw.githubusercontent.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/master/ch_09/data/winequality-red.csv')\n",
        "\n",
        "winew['kind'] = 'white'      #Adding column for kind\n",
        "winer['kind'] = 'red'\n",
        "\n",
        "frames = [winew, winer]\n",
        "wine = pd.concat(frames)     #Combining datasets\n",
        "\n",
        "wine['kind'] = wine['kind'].replace(to_replace = ['white', 'red'], value = [0, 1])      #Changing kind to numeric\n",
        "\n",
        "X = wine.drop(['kind', 'quality'], axis = 1)\n",
        "y = wine['kind']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)        #Splitting up data to training and test set\n",
        "\n",
        "sc = StandardScaler()\n",
        "\n",
        "X_train = sc.fit_transform(X_train)                           #Scaling data\n",
        "X_test = sc.fit_transform(X_test)\n",
        "\n",
        "kmeans = KMeans(n_clusters=2, random_state=0)                 #Introducing KMeans and defining its parameters\n",
        "\n",
        "kmeans.fit(X_train, y_train)                                  #Training model\n",
        "\n",
        "kmeans_pred = kmeans.predict(X_test)                          #Testing predictive power on the test set\n",
        "\n",
        "print(classification_report(y_test, kmeans_pred))             #Classification report\n",
        "\n",
        "print(fowlkes_mallows_score(y_test, kmeans_pred))             #The Fowlkes-Mallows index (geometric mean between of the precision and recall)\n",
        "\n",
        "clf = NearestCentroid()\n",
        "clf.fit(X, y)\n",
        "\n",
        "print(clf.centroids_)                                         #Centroids\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "1. Build a clustering model to distinguish between red and white wine by their\n",
        "chemical properties:\n",
        "a) Combine the red and white wine datasets (data/winequality-red.csv\n",
        "and data/winequality-white.csv, respectively) and add a column for the\n",
        "kind of wine (red or white).\n",
        "b) Perform some initial EDA.\n",
        "c) Build and fit a pipeline that scales the data and then uses k-means clustering to\n",
        "make two clusters. Be sure not to use the quality column.\n",
        "d) Use the Fowlkes-Mallows Index (the fowlkes_mallows_score() function\n",
        "is in sklearn.metrics) to evaluate how well k-means is able to make the\n",
        "distinction between red and white wine.\n",
        "e) Find the center of each cluster.\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import fowlkes_mallows_score\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "\n",
        "pd.set_option('display.max_rows', 200)\n",
        "pd.set_option('display.max_columns', 200)\n",
        "\n",
        "winew = pd.read_csv('https://raw.githubusercontent.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/master/ch_09/data/winequality-white.csv', delimiter = ';')\n",
        "winer = pd.read_csv('https://raw.githubusercontent.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/master/ch_09/data/winequality-red.csv')\n",
        "\n",
        "winew['kind'] = 'white'      #Adding column for kind\n",
        "winer['kind'] = 'red'\n",
        "\n",
        "frames = [winew, winer]\n",
        "wine = pd.concat(frames)     #Combining datasets\n",
        "\n",
        "wine['kind'] = wine['kind'].replace(to_replace = ['white', 'red'], value = [0, 1])      #Changing kind to numeric\n",
        "\n",
        "X = wine.drop(['kind', 'quality'], axis = 1)\n",
        "y = wine['kind']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)        #Splitting up data to training and test set\n",
        "\n",
        "pipeline_kmeans = Pipeline([                                                        #Setting up pipeline\n",
        "                            ('Scaling', StandardScaler()),                          #Scaling (StandardScaler)\n",
        "                            ('kmeans', KMeans(n_clusters=2, random_state=0))        #Model: KMeans\n",
        "                            ]).fit(X_train)                                         #Training model\n",
        "\n",
        "\n",
        "kmeans_pred = pipeline_kmeans.predict(X_test)               #Testing predictive power on the test set\n",
        "\n",
        "print(classification_report(y_test, kmeans_pred))           #Classification report\n",
        "\n",
        "print(fowlkes_mallows_score(y_test, kmeans_pred))           #The Fowlkes-Mallows index (geometric mean between of the precision and recall)\n",
        "\n",
        "clf = NearestCentroid()\n",
        "clf.fit(X, y)\n",
        "\n",
        "print(clf.centroids_)                                       #Centroids\n"
      ],
      "metadata": {
        "id": "IwI_jkBSc8nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "2. Predict star temperature:\n",
        "a) Using the data/stars.csv file, perform some initial EDA and then build\n",
        "a linear regression model of all the numeric columns to predict the temperature\n",
        "of the star.\n",
        "b) Train the model on 75% of the initial data.\n",
        "c) Calculate the R2 and RMSE of the model.\n",
        "d) Find the coefficients for each regressor and the intercept of the linear regression\n",
        "equation.\n",
        "e) Visualize the residuals using the plot_residuals() function from the\n",
        "ml_utils.regression module.\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import statsmodels.api as sm\n",
        "from yellowbrick.regressor import ResidualsPlot\n",
        "\n",
        "pd.set_option('display.max_rows', 200)\n",
        "pd.set_option('display.max_columns', 200)\n",
        "\n",
        "stars = pd.read_csv('https://raw.githubusercontent.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/master/ch_09/data/stars.csv')\n",
        "\n",
        "\n",
        "numeric = stars.drop(['spectraltype', 'name', 'magH'], axis = 1)      #Dropping non-numeric columns\n",
        "numeric = numeric.dropna()                                            #Dropping rows with missing values\n",
        "\n",
        "X = numeric.drop('temperature', axis = 1)                             #Data columns\n",
        "y = numeric.temperature                                               #Target column\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)        #Splitting up data to training and test set\n",
        "\n",
        "\n",
        "lr = LinearRegression().fit(X_train, y_train)                                 #Training model\n",
        "\n",
        "print('R-squared: ', lr.score(X_test, y_test))                                #R-squared\n",
        "\n",
        "print('RMSE: ', np.sqrt(mean_squared_error(y_test, lr.predict(X_test))))      #RMSE\n",
        "\n",
        "print('Coefficients of the linear model: ', [(coef, feature) for coef, feature in zip(lr.coef_, X_train.columns)])      #Coeffcients of the linear model\n",
        "\n",
        "print('Y-intercept of the linear model: ', lr.intercept_)       #Y-intercept of the linear model\n",
        "\n",
        "model = LinearRegression()\n",
        "visualizer = ResidualsPlot(model, hist=False)\n",
        "\n",
        "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
        "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
        "visualizer.show()                 # Finalize and render the figure\n",
        "\n",
        "resid = (y_test - lr.predict(X_test))\n",
        "sns.kdeplot(resid)"
      ],
      "metadata": {
        "id": "GXvnLAGb4t0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "3. Classify planets that have shorter years than Earth:\n",
        "a) Using the data/planets.csv file, build a logistic regression model with the\n",
        "eccentricity, semimajoraxis, and mass columns as regressors. You will\n",
        "need to make a new column to use for the y (year shorter than Earth).\n",
        "b) Find the accuracy score.\n",
        "c) Use the classification_report() function from scikit-learn to see\n",
        "the precision, recall, and F1 score for each class.\n",
        "d) With the plot_roc() function from the ml_utils.classification\n",
        "module, plot the ROC curve.\n",
        "e) Create a confusion matrix using the confusion_matrix_visual() function\n",
        "from the ml_utils.classification module.\n",
        "'''\n",
        "#!pip install scikit-plot\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "import scikitplot as skplt\n",
        "\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.max_columns', 100)\n",
        "\n",
        "planets = pd.read_csv('https://raw.githubusercontent.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/master/ch_09/data/planets.csv')\n",
        "\n",
        "\n",
        "planets['y'] = np.where(planets['period'] < 365.2422, True, False)              # Creating year classification column\n",
        "\n",
        "planets2 = planets[['eccentricity', 'semimajoraxis', 'mass', 'y']].dropna()     # Dropping rows with missing values\n",
        "\n",
        "X = planets2.drop('y', axis = 1)     #Data set\n",
        "y = planets2.y                       #Target set\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0, stratify = y)        #Splitting up data to training and test set\n",
        "\n",
        "logreg = LogisticRegression(random_state = 0).fit(X_train, y_train)             #Training model\n",
        "\n",
        "display(accuracy_score(y_test, logreg.predict(X_test)))                         # Accuracy score\n",
        "print(classification_report(y_test, logreg.predict(X_test)))                    # Classification report\n",
        "\n",
        "y_true = y_test                                           # Plotting ROC curve\n",
        "y_probas = logreg.predict_proba(X_test)\n",
        "skplt.metrics.plot_roc_curve(y_true, y_probas)\n",
        "plt.show()\n",
        "\n",
        "print(confusion_matrix(y_test, logreg.predict(X_test)))   # Confusion matrix"
      ],
      "metadata": {
        "id": "fgr4QYugMUAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "4. Multiclass classification of white wine quality:\n",
        "a) Using the data/winequality-white.csv file, perform some initial EDA on\n",
        "the white wine data. Be sure to look at how many wines had a given quality score.\n",
        "b) Build a pipeline to standardize the data and fit a multiclass logistic regression\n",
        "model. Pass multi_class='multinomial' and max_iter=1000 to the\n",
        "LogisticRegression constructor.\n",
        "c) Look at the classification report for your model.\n",
        "d) Create a confusion matrix using the confusion_matrix_visual() function\n",
        "from the ml_utils.classification module. This will work as is for\n",
        "multiclass classification problems.\n",
        "e) Extend the plot_roc() function to work for multiple class labels. To do so,\n",
        "you will need to create a ROC curve for each class label (which are quality scores\n",
        "here), where a true positive is correctly predicting that quality score and a false\n",
        "positive is predicting any other quality score. Note that ml_utils has a function\n",
        "for this, but try to build your own implementation.\n",
        "f) Extend the plot_pr_curve() function to work for multiple class labels\n",
        "by following a similar method to part e). However, give each class its own\n",
        "subplot. Note that ml_utils has a function for this, but try to build your own\n",
        "implementation.\n",
        "'''\n",
        "#!pip install scikit-plot\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import fowlkes_mallows_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import scikitplot as skplt\n",
        "\n",
        "\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.max_columns', 100)\n",
        "\n",
        "wine = pd.read_csv('https://raw.githubusercontent.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/master/ch_09/data/winequality-white.csv', delimiter = ';')\n",
        "\n",
        "print('Wine quality counts:\\n',wine.quality.value_counts())                 # Checking quality scores\n",
        "print('Number of rows with missing values: ', wine.isnull().sum().sum())     # Checking missing values               \n",
        "\n",
        "X = wine[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',     # Data set\n",
        "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
        "       'pH', 'sulphates', 'alcohol']]\n",
        "\n",
        "y = wine['quality']                                                                 # Target set\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0, stratify = y)          # Splitting data up into train and test set\n",
        "\n",
        "wine_pipeline = Pipeline([('Scaler', StandardScaler()),                                                              # Pipeline: Scaling\n",
        "                          ('Model', LogisticRegression(multi_class='multinomial', max_iter=1000, random_state = 0))  #           Model: Logistic regression\n",
        "                          ]).fit(X_train, y_train)                                                                   #           Training model with X_train\n",
        "\n",
        "print(classification_report(y_test, wine_pipeline.predict(X_test)))       # Classification report\n",
        "\n",
        "print(confusion_matrix(y_test, wine_pipeline.predict(X_test)))            # Confusion matrix\n",
        "\n",
        "y_true = y_test                                                           # Plotting ROC curve\n",
        "y_probas = wine_pipeline.predict_proba(X_test)\n",
        "skplt.metrics.plot_roc_curve(y_true, y_probas, figsize = (12,12))\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "n-J2thb6NJFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "5. We have seen how easy the scikit-learn API is to navigate, making it a cinch\n",
        "to change which algorithm we are using for our model. Rebuild the red wine quality\n",
        "model that we created in this chapter using an SVM instead of logistic regression.\n",
        "We haven't discussed this model, but you should still be able to use it in scikitlearn.\n",
        "Check out the link in the Further reading section to learn more about the\n",
        "algorithm. Some guidance for this exercise is as follows:\n",
        "a) You will need to use the SVC (support vector classifier) class from scikitlearn,\n",
        "which can be found at https://scikit-learn.org/stable/\n",
        "modules/generated/sklearn.svm.SVC.html.\n",
        "b) Use C=5 as an argument to the SVC constructor.\n",
        "c) Pass probability=True to the SVC constructor to be able to use the\n",
        "predict_proba() method.\n",
        "d) Build a pipeline first using the StandardScaler class and then the SVC class.\n",
        "e) Be sure to look at the classification report, precision-recall curve, and confusion\n",
        "matrix for the model.\n",
        "\n",
        "'''\n",
        "\n",
        "#!pip install scikit-plot\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve\n",
        "from sklearn.metrics import fowlkes_mallows_score\n",
        "from sklearn.svm import SVC\n",
        "import scikitplot as skplt\n",
        "\n",
        "pd.set_option('display.max_rows', 200)\n",
        "pd.set_option('display.max_columns', 200)\n",
        "\n",
        "wine = pd.read_csv('https://raw.githubusercontent.com/stefmolin/Hands-On-Data-Analysis-with-Pandas-2nd-edition/master/ch_09/data/winequality-red.csv')\n",
        "\n",
        "wine['quality2'] = pd.cut(wine.quality, bins=[0, 6, 10], labels=[0, 1])\n",
        "\n",
        "X = wine.drop(['quality', 'quality2'], axis = 1)\n",
        "y = wine.quality2\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0, stratify = y)\n",
        "\n",
        "wine_pipeline = Pipeline([\n",
        "                          ('Scaler', StandardScaler()),\n",
        "                          ('SVM', SVC(C = 5, random_state = 0, probability = True))\n",
        "                          ]).fit(X_train, y_train)\n",
        "\n",
        "print(classification_report(y_test, wine_pipeline.predict(X_test)))       # Classification report\n",
        "print(confusion_matrix(y_test, wine_pipeline.predict(X_test)))            # Confusion matrix\n",
        "\n",
        "y_pred = wine_pipeline.predict(X_test)                                    # Confusion matrix plot\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "y_probas = wine_pipeline.predict_proba(X_test)                            # Precision-recall curve\n",
        "skplt.metrics.plot_precision_recall(y_test, y_probas)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bFRv_S67lmWG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}